# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ•°æ®åŠ è½½å™¨ - V4.2/V4.2.1

æ•´åˆåŠŸèƒ½:
1. åŸºç¡€æ•°æ®åŠ è½½ï¼ˆload_train_eval_separatelyç­‰ï¼‰
2. ä¿¡å·åˆ‡ç‰‡ï¼ˆslice_raw_signalï¼‰
3. å›¾æ„å»ºï¼ˆbuild_plv_adjacency_matrixï¼‰
4. DEç‰¹å¾è®¡ç®—ï¼ˆå¯é€‰ï¼Œä¿ç•™å‘åå…¼å®¹ï¼‰

ç‰ˆæœ¬è¯´æ˜:
- ä¸V4.1å®Œå…¨ç›¸åŒï¼Œä½†ä¸ºV4.2ç³»åˆ—ç‹¬ç«‹ç»´æŠ¤
- ä¿è¯æ¯ä¸ªç‰ˆæœ¬éƒ½æœ‰å®Œæ•´çš„ä»£ç æ–‡ä»¶é›†

ä½¿ç”¨èŒƒå›´: V3.6, V4.1åŠåç»­ç‰ˆæœ¬
"""
import os
import numpy as np
from scipy.io import loadmat
from scipy.signal import hilbert, butter, filtfilt, sosfilt
import torch
from tqdm import tqdm


# ============================================================
# åŸºç¡€æ•°æ®åŠ è½½å‡½æ•°
# ============================================================

def load_train_eval_separately(mat_path, subject_id, trial_start_offset=2.0, trial_length=4.0, return_run_indices=False):
    """
    åˆ†åˆ«åŠ è½½è®­ç»ƒé›†(T)å’Œè¯„ä¼°é›†(E) - è¿”å›åŸå§‹æœªæ»¤æ³¢æ•°æ®

    âš ï¸ é‡è¦: è¿”å›æœªæ»¤æ³¢æ•°æ®ï¼Œç”±åç»­æµç¨‹æ ¹æ®éœ€è¦æ»¤æ³¢
    - é¿å…åŒé‡æ»¤æ³¢bug
    - å…è®¸ä¸åŒæµä½¿ç”¨ä¸åŒæ»¤æ³¢å‚æ•°

    Args:
        mat_path: æ•°æ®ç›®å½•è·¯å¾„
        subject_id: è¢«è¯•ID (e.g., 'A01')
        trial_start_offset: MIå¼€å§‹æ—¶é—´ï¼ˆé»˜è®¤2.0ç§’ï¼‰
        trial_length: MIæŒç»­æ—¶é—´ï¼ˆé»˜è®¤4.0ç§’ï¼‰
        return_run_indices: æ˜¯å¦è¿”å›runç´¢å¼•ï¼ˆç”¨äºrunçº§åŠ æƒï¼‰

    Returns:
        X_train: (N_train, 22, 1000) è®­ç»ƒé›†åŸå§‹EEG
        y_train: (N_train,) è®­ç»ƒé›†æ ‡ç­¾ (0-3)
        X_eval: (N_eval, 22, 1000) è¯„ä¼°é›†åŸå§‹EEG
        y_eval: (N_eval,) è¯„ä¼°é›†æ ‡ç­¾ (0-3)
        run_indices_train: (N_train,) è®­ç»ƒé›†runç´¢å¼• (0-5)ï¼Œä»…å½“return_run_indices=Trueæ—¶è¿”å›
        run_indices_eval: (N_eval,) è¯„ä¼°é›†runç´¢å¼• (0-5)ï¼Œä»…å½“return_run_indices=Trueæ—¶è¿”å›
    """
    print(f"æ­£åœ¨åŠ è½½è¢«è¯• {subject_id} (åˆ†ç¦»Tå’ŒE)...")
    print(f"  âœ… MIæ—¶é—´çª—: {trial_start_offset}s-{trial_start_offset+trial_length}s")
    print(f"  âš ï¸ è¿”å›åŸå§‹ä¿¡å·ï¼ˆæœªæ»¤æ³¢ï¼‰")
    if return_run_indices:
        print(f"  ğŸ“Š è¿”å›runç´¢å¼•ï¼ˆç”¨äºrunçº§åŠ æƒï¼‰")

    # åŠ è½½è®­ç»ƒé›†T
    train_file = os.path.join(mat_path, f'{subject_id}T.mat')
    if return_run_indices:
        X_train, y_train, run_indices_train = extract_trials_from_mat(train_file, trial_start_offset, trial_length, return_run_indices=True)
    else:
        X_train, y_train = extract_trials_from_mat(train_file, trial_start_offset, trial_length, return_run_indices=False)
    print(f"  T (è®­ç»ƒé›†): {X_train.shape[0]} trials")
    if return_run_indices:
        print(f"    Runåˆ†å¸ƒ: {[np.sum(run_indices_train == r) for r in range(6)]}")

    # åŠ è½½è¯„ä¼°é›†E
    eval_file = os.path.join(mat_path, f'{subject_id}E.mat')
    if return_run_indices:
        X_eval, y_eval, run_indices_eval = extract_trials_from_mat(eval_file, trial_start_offset, trial_length, return_run_indices=True)
    else:
        X_eval, y_eval = extract_trials_from_mat(eval_file, trial_start_offset, trial_length, return_run_indices=False)
    print(f"  E (è¯„ä¼°é›†): {X_eval.shape[0]} trials")
    if return_run_indices:
        print(f"    Runåˆ†å¸ƒ: {[np.sum(run_indices_eval == r) for r in range(6)]}")

    # æ ‡ç­¾è½¬æ¢: 1-4 â†’ 0-3
    y_train = y_train - 1
    y_eval = y_eval - 1

    print(f"  è®­ç»ƒé›†: {X_train.shape}, æ¯ç±»: {np.bincount(y_train)}")
    print(f"  è¯„ä¼°é›†: {X_eval.shape}, æ¯ç±»: {np.bincount(y_eval)}")
    print(f"  âœ… è¿”å›åŸå§‹æœªæ»¤æ³¢æ•°æ®")

    if return_run_indices:
        return X_train, y_train, X_eval, y_eval, run_indices_train, run_indices_eval
    return X_train, y_train, X_eval, y_eval


def load_single_session(mat_path, subject_id, session='T', trial_start_offset=2.0, trial_length=4.0, return_run_indices=False):
    """
    åŠ è½½å•ä¸ªsessionçš„æ•°æ®ï¼ˆTæˆ–Eï¼‰

    Args:
        mat_path: æ•°æ®ç›®å½•
        subject_id: è¢«è¯•ID (e.g., 'A01')
        session: 'T' æˆ– 'E'
        trial_start_offset: trialå¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        trial_length: trialé•¿åº¦ï¼ˆç§’ï¼‰
        return_run_indices: æ˜¯å¦è¿”å›runç´¢å¼•

    Returns:
        X_session: (N, 22, 1000)
        y_session: (N,)
        run_indices_session: (N,) ä»…å½“return_run_indices=Trueæ—¶è¿”å›
    """
    session = session.upper()
    if session not in ['T', 'E']:
        raise ValueError(f"sessionå¿…é¡»ä¸º'T'æˆ–'E'ï¼Œæ”¶åˆ°: {session}")

    print(f"æ­£åœ¨åŠ è½½è¢«è¯• {subject_id} çš„å•ä¸ªsession: {session}")
    print(f"  âœ… MIæ—¶é—´çª—: {trial_start_offset}s-{trial_start_offset+trial_length}s")
    print(f"  âš ï¸ è¿”å›åŸå§‹ä¿¡å·ï¼ˆæœªæ»¤æ³¢ï¼‰")

    mat_file = os.path.join(mat_path, f'{subject_id}{session}.mat')
    if not os.path.exists(mat_file):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°{session} sessionæ–‡ä»¶: {mat_file}")

    if return_run_indices:
        X_session, y_session, run_indices = extract_trials_from_mat(
            mat_file, trial_start_offset, trial_length, return_run_indices=True
        )
    else:
        X_session, y_session = extract_trials_from_mat(
            mat_file, trial_start_offset, trial_length, return_run_indices=False
        )

    if X_session is None:
        raise RuntimeError(f"{subject_id}{session} æ— æœ‰æ•ˆtrial")

    y_session = y_session - 1

    print(f"  Session {session}: {X_session.shape[0]} trials, æ¯ç±»: {np.bincount(y_session)}")
    if return_run_indices:
        print(f"    Runåˆ†å¸ƒ: {[np.sum(run_indices == r) for r in range(6)]}")

    if return_run_indices:
        return X_session, y_session, run_indices
    return X_session, y_session


def extract_trials_from_mat(mat_file, trial_start_offset, trial_length, return_run_indices=False):
    """
    ä».matæ–‡ä»¶æå–trials

    Args:
        mat_file: .matæ–‡ä»¶è·¯å¾„
        trial_start_offset: trialå¼€å§‹åç§»ï¼ˆç§’ï¼‰
        trial_length: trialé•¿åº¦ï¼ˆç§’ï¼‰
        return_run_indices: æ˜¯å¦è¿”å›runç´¢å¼•

    Returns:
        X: (N, 22, T) EEGæ•°æ®
        y: (N,) æ ‡ç­¾ï¼ˆåŸå§‹1-4ï¼‰
        run_indices: (N,) runç´¢å¼• (0-5)ï¼Œä»…å½“return_run_indices=Trueæ—¶è¿”å›
    """
    data = loadmat(mat_file)
    data_array = data['data']

    X_list, y_list, run_list = [], [], []
    run_counter = 0  # ç”¨äºè¿ç»­ç¼–å·runç´¢å¼•

    for session_idx in range(data_array.shape[1]):
        session = data_array[0, session_idx]

        X_continuous = session['X'][0, 0]  # (timepoints, channels)
        y_labels = session['y'][0, 0]  # (n_trials, 1)
        trial_starts = session['trial'][0, 0]  # (n_trials, 1)
        fs = int(session['fs'][0, 0][0, 0])

        if len(y_labels) == 0:
            continue

        offset_samples = int(trial_start_offset * fs)
        length_samples = int(trial_length * fs)

        # åªä½¿ç”¨å‰22ä¸ªé€šé“ï¼ˆæ ‡å‡†EEGé€šé“ï¼‰
        X_continuous = X_continuous[:, :22]

        for trial_idx in range(len(trial_starts)):
            trial_start = int(trial_starts[trial_idx, 0])

            start_idx = trial_start + offset_samples
            end_idx = start_idx + length_samples

            if end_idx <= X_continuous.shape[0]:
                # è½¬ç½®: (T, C) â†’ (C, T)
                trial_data = X_continuous[start_idx:end_idx, :].T
                X_list.append(trial_data)
                y_list.append(y_labels[trial_idx, 0])
                run_list.append(run_counter)  # ä½¿ç”¨è¿ç»­çš„runç´¢å¼•

        # å¦‚æœè¿™ä¸ªsessionæœ‰æ•°æ®ï¼Œrunè®¡æ•°å™¨+1
        if len(y_labels) > 0:
            run_counter += 1

    if len(X_list) == 0:
        if return_run_indices:
            return None, None, None
        return None, None

    if return_run_indices:
        return np.array(X_list), np.array(y_list), np.array(run_list)
    return np.array(X_list), np.array(y_list)


# ============================================================
# ä¿¡å·åˆ‡ç‰‡å‡½æ•°ï¼ˆV3.6+ï¼‰
# ============================================================

def slice_raw_signal(X, n_slices=5, verbose=True):
    """
    å°†åŸå§‹EEGä¿¡å·åˆ‡ç‰‡ï¼ˆç”¨äºGNNèŠ‚ç‚¹ç‰¹å¾æå–ï¼‰
    
    Args:
        X: (N, C, T) åŸå§‹EEGæ•°æ®
        n_slices: åˆ‡ç‰‡æ•°é‡
        
    Returns:
        X_sliced: (N, n_slices, C, slice_length)
    
    Example:
        X: (288, 22, 1000)
        n_slices=5
        â†’ X_sliced: (288, 5, 22, 200)
    """
    N, C, T = X.shape
    slice_length = T // n_slices
    
    if verbose:
        print(f"  ğŸ”ª åˆ‡ç‰‡åŸå§‹ä¿¡å·: {n_slices}ç‰‡ Ã— {slice_length}ç‚¹/ç‰‡")
    
    X_sliced = np.zeros((N, n_slices, C, slice_length), dtype=np.float32)
    
    for i in range(n_slices):
        start = i * slice_length
        end = (i + 1) * slice_length
        X_sliced[:, i, :, :] = X[:, :, start:end]
    
    if verbose:
        print(f"  âœ… åˆ‡ç‰‡å®Œæˆ: {X_sliced.shape}")
    return X_sliced


# ============================================================
# å›¾æ„å»ºå‡½æ•°
# ============================================================

def build_plv_adjacency_matrix(X, threshold=0.8):
    """
    æ„å»ºPLVï¼ˆç›¸ä½é”å®šå€¼ï¼‰é‚»æ¥çŸ©é˜µ
    
    Args:
        X: (N, C, T) EEGæ•°æ®
        threshold: PLVé˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼‰
    
    Returns:
        plv_normalized: (C, C) å½’ä¸€åŒ–PLVé‚»æ¥çŸ©é˜µ
    """
    print(f"  æ„å»ºPLVé‚»æ¥çŸ©é˜µ (threshold={threshold})...")
    
    n_trials, n_channels, n_timepoints = X.shape
    
    # è®¡ç®—è§£æä¿¡å·å’Œç¬æ—¶ç›¸ä½
    X_analytic = hilbert(X, axis=2)
    instantaneous_phase = np.angle(X_analytic)
    
    # åˆå§‹åŒ–PLVçŸ©é˜µ
    plv_matrix = np.zeros((n_channels, n_channels))
    
    # è®¡ç®—æ‰€æœ‰é€šé“å¯¹çš„PLV
    for i in range(n_channels):
        for j in range(i, n_channels):
            if i == j:
                plv_matrix[i, j] = 1.0
                continue
            
            # ç›¸ä½å·®
            phase_diff = instantaneous_phase[:, i, :] - instantaneous_phase[:, j, :]
            
            # PLVè®¡ç®—
            plv = np.abs(np.mean(np.exp(1j * phase_diff)))
            plv_matrix[i, j] = plv_matrix[j, i] = plv
    
    # é˜ˆå€¼å¤„ç†
    plv_matrix[plv_matrix < threshold] = 0
    np.fill_diagonal(plv_matrix, 1.0)
    
    # å½’ä¸€åŒ–: D^(-1/2) * A * D^(-1/2)
    D = np.sum(plv_matrix, axis=1)
    D_inv_sqrt = np.power(D, -0.5)
    D_inv_sqrt[np.isinf(D_inv_sqrt)] = 0.
    D_matrix_inv_sqrt = np.diag(D_inv_sqrt)
    plv_normalized = np.matmul(np.matmul(D_matrix_inv_sqrt, plv_matrix), D_matrix_inv_sqrt)
    
    print(f"  âœ… PLVçŸ©é˜µå®Œæˆ")
    
    return plv_normalized


def normalize_adjacency_matrix(adj_matrix):
    """
    å½’ä¸€åŒ–é‚»æ¥çŸ©é˜µï¼ˆä½¿ç”¨PyTorchï¼‰
    
    Args:
        adj_matrix: numpy arrayæˆ–torch tensor
    
    Returns:
        normalized_adj: torch tensor
    """
    if isinstance(adj_matrix, np.ndarray):
        adj_matrix = torch.FloatTensor(adj_matrix)
    
    D = torch.sum(adj_matrix, dim=1)
    D_inv_sqrt = torch.pow(D, -0.5)
    D_inv_sqrt[torch.isinf(D_inv_sqrt)] = 0.
    D_matrix_inv_sqrt = torch.diag(D_inv_sqrt)
    
    return torch.matmul(torch.matmul(D_matrix_inv_sqrt, adj_matrix), D_matrix_inv_sqrt)


# ============================================================
# DEç‰¹å¾è®¡ç®—ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼ŒV3.6+ä¸ä½¿ç”¨ï¼‰
# ============================================================

def compute_de_features(X, fs=250, cache_file=None):
    """
    é¢„è®¡ç®—å¾®åˆ†ç†µï¼ˆDEï¼‰ç‰¹å¾
    
    æ³¨æ„: V3.6/V4.1ä¸ä½¿ç”¨DEç‰¹å¾ï¼Œæ­¤å‡½æ•°ä¿ç•™å‘åå…¼å®¹
    
    Args:
        X: (n_trials, n_channels, n_timepoints) EEGæ•°æ®
        fs: é‡‡æ ·ç‡
        cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    
    Returns:
        de_features: (n_trials, n_channels, 5) 5ä¸ªé¢‘å¸¦çš„DEç‰¹å¾
    """
    # æ£€æŸ¥ç¼“å­˜
    if cache_file and os.path.exists(cache_file):
        print(f"  âœ… ä»ç¼“å­˜åŠ è½½DEç‰¹å¾: {cache_file}")
        return np.load(cache_file)
    
    print(f"  ğŸ”§ é¢„è®¡ç®—DEç‰¹å¾ï¼ˆ5é¢‘å¸¦ï¼‰...")
    
    # 5ä¸ªé¢‘å¸¦ï¼šÎ´, Î¸, Î¼, Î², Î³
    bands = [(1, 4), (4, 8), (8, 13), (13, 30), (30, 40)]
    
    n_trials, n_channels, n_timepoints = X.shape
    de_features = np.zeros((n_trials, n_channels, len(bands)), dtype=np.float32)
    
    # è®¾è®¡æ»¤æ³¢å™¨
    nyq = fs / 2
    sos_filters = []
    for low, high in bands:
        sos = butter(4, [low/nyq, high/nyq], btype='band', output='sos')
        sos_filters.append(sos)
    
    # æ‰¹é‡è®¡ç®—
    for trial in range(n_trials):
        if trial % 100 == 0:
            print(f"    å¤„ç† trial {trial}/{n_trials}...")
        
        for ch in range(n_channels):
            sig = X[trial, ch, :]
            
            for band_idx, sos in enumerate(sos_filters):
                # å¸¦é€šæ»¤æ³¢
                filtered = sosfilt(sos, sig)
                
                # å¾®åˆ†ç†µ: 0.5 * log(2Ï€ e ÏƒÂ²)
                var = np.var(filtered)
                de = 0.5 * np.log(2 * np.pi * np.e * (var + 1e-10))
                de_features[trial, ch, band_idx] = de
    
    # ä¿å­˜ç¼“å­˜
    if cache_file:
        os.makedirs(os.path.dirname(cache_file), exist_ok=True)
        np.save(cache_file, de_features)
        print(f"  âœ… DEç‰¹å¾å·²ä¿å­˜: {cache_file}")
    
    print(f"  âœ… DEç‰¹å¾è®¡ç®—å®Œæˆ: {de_features.shape}")
    
    return de_features


def compute_sliced_de_features(X, fs=250, n_slices=5, cache_file=None):
    """
    é¢„è®¡ç®—åˆ‡ç‰‡çš„å¾®åˆ†ç†µï¼ˆDEï¼‰ç‰¹å¾
    
    æ³¨æ„: V3.6/V4.1ä¸ä½¿ç”¨ï¼Œæ­¤å‡½æ•°ä¿ç•™å‘åå…¼å®¹
    
    Args:
        X: (n_trials, n_channels, n_timepoints) EEGæ•°æ®
        fs: é‡‡æ ·ç‡
        n_slices: åˆ‡ç‰‡æ•°é‡
        cache_file: ç¼“å­˜æ–‡ä»¶è·¯å¾„
    
    Returns:
        de_features_sliced: (n_trials, n_slices, n_channels, 5)
    """
    # æ£€æŸ¥ç¼“å­˜
    if cache_file and os.path.exists(cache_file):
        print(f"  âœ… ä»ç¼“å­˜åŠ è½½ Sliced DE ç‰¹å¾: {cache_file}")
        return np.load(cache_file)
    
    print(f"  ğŸ”§ é¢„è®¡ç®— Sliced DE ç‰¹å¾ ({n_slices} slices, 5 bands)...")
    
    # 5ä¸ªé¢‘å¸¦
    bands = [(1, 4), (4, 8), (8, 13), (13, 30), (30, 40)]
    
    n_trials, n_channels, n_timepoints = X.shape
    slice_length = n_timepoints // n_slices
    
    if slice_length == 0:
        raise ValueError(f"æ—¶é—´ç‚¹ {n_timepoints} å¤ªçŸ­ï¼Œæ— æ³•åˆ†ä¸º {n_slices} ç‰‡")
    
    print(f"  æ¯ä¸ªåˆ‡ç‰‡é•¿åº¦: {slice_length} ä¸ªæ—¶é—´ç‚¹ ({slice_length/fs:.2f}ç§’)")
    
    # åˆå§‹åŒ–ç»“æœ
    de_features_sliced = np.zeros((n_trials, n_slices, n_channels, len(bands)), dtype=np.float32)
    
    # è®¾è®¡æ»¤æ³¢å™¨
    nyq = fs / 2
    sos_filters = []
    for low, high in bands:
        low = max(low, 0.1)
        high = min(high, nyq - 0.1)
        if low >= high:
            continue
        sos = butter(4, [low/nyq, high/nyq], btype='band', output='sos')
        sos_filters.append(sos)
    
    # æ‰¹é‡è®¡ç®—
    for trial in tqdm(range(n_trials), desc="  è®¡ç®—Sliced DE"):
        for sl_idx in range(n_slices):
            start = sl_idx * slice_length
            end = (sl_idx + 1) * slice_length
            
            for ch in range(n_channels):
                sig_slice = X[trial, ch, start:end]
                
                for band_idx, sos in enumerate(sos_filters):
                    filtered = sosfilt(sos, sig_slice)
                    var = np.var(filtered)
                    de = 0.5 * np.log(2 * np.pi * np.e * (var + 1e-10))
                    de_features_sliced[trial, sl_idx, ch, band_idx] = de
    
    # ä¿å­˜ç¼“å­˜
    if cache_file:
        os.makedirs(os.path.dirname(cache_file), exist_ok=True)
        np.save(cache_file, de_features_sliced)
        print(f"  âœ… Sliced DE ç‰¹å¾å·²ä¿å­˜: {cache_file}")
    
    print(f"  âœ… Sliced DE ç‰¹å¾è®¡ç®—å®Œæˆ: {de_features_sliced.shape}")
    
    return de_features_sliced


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================

if __name__ == "__main__":
    print("="*80)
    print("ğŸ§ª ç»Ÿä¸€æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("="*80)
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    print("\n1. æµ‹è¯•æ•°æ®åŠ è½½...")
    X_train, y_train, X_eval, y_eval = load_train_eval_separately(
        'BCIIV2a_mat', 'A01'
    )
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    print(f"   è®­ç»ƒé›†: {X_train.shape}")
    print(f"   è¯„ä¼°é›†: {X_eval.shape}")
    
    # æµ‹è¯•ä¿¡å·åˆ‡ç‰‡
    print("\n2. æµ‹è¯•ä¿¡å·åˆ‡ç‰‡...")
    X_train_sliced = slice_raw_signal(X_train, n_slices=5)
    print(f"âœ… åˆ‡ç‰‡æˆåŠŸ: {X_train_sliced.shape}")
    
    # æµ‹è¯•PLVå›¾æ„å»º
    print("\n3. æµ‹è¯•PLVå›¾æ„å»º...")
    adj_plv = build_plv_adjacency_matrix(X_train, threshold=0.8)
    print(f"âœ… PLVçŸ©é˜µæ„å»ºæˆåŠŸ: {adj_plv.shape}")
    
    # æµ‹è¯•å½’ä¸€åŒ–
    print("\n4. æµ‹è¯•é‚»æ¥çŸ©é˜µå½’ä¸€åŒ–...")
    adj_norm = normalize_adjacency_matrix(adj_plv)
    print(f"âœ… å½’ä¸€åŒ–æˆåŠŸ: {adj_norm.shape}, type: {type(adj_norm)}")
    
    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("="*80)
